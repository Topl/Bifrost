params {

  ### Node Behavior ###
  # Dev mode toggle
  devMode = true
  # Use the gui for runtime user interaction
  useGui = false
  # Path for data output files
  dataFileDir = "data"
  # Path for user defined key files
  keyFileDir = "keys"
  # The minumum index of local holders to start, set to -1 for no holders
  holderIndexMin = 0
  # The maximum index of local holders to start, set to -1 for no holders
  holderIndexMax = 31
  # Time server for NTP sync
  timeServer = "time-a.nist.gov"
  # Seed entropy for coordinator and stakeholders, set randomFlag = false to use this seed
  inputSeed = "default"
  # Set to true for random input seed, the new seed will be displayed by coordinator
  randomFlag = true
  # Transaction confirmation depth in blocks
  confirmationDepth = 10
  # Time out for dropped messages from coordinator, in seconds
  waitTime = 3600
  # Duration between update tics that stakeholder actors send to themselves, in milliseconds
  updateTime = 10
  # Duration between update tics that coordinator and router actors send to themselves, in milliseconds
  commandUpdateTime = 10
  # Print Stakeholder 0 status per slot if true
  printFlag = true
  # Print Stakeholder 0 execution time per slot if true
  timingFlag = true


  ### Performance Settings ###
  # Max number of entries in cache for block and state storage
  cacheSize = 50
  # Database refresh interval in slots
  refreshInterval = 5000
  # Interval in slots between localChain save to disk
  chainStoreInterval = 500
  # KES save to disk time interval in slots
  kesStoreInterval = 5000
  # Interval between ReturnBlocks send commands in RequestTineProvider, in milliseconds
  requestTineInterval = 200
  # Number of simulation message processors to instantiate for local delay model
  numMessageProcessors = 8
  # When true, if system cpu load is too high the coordinator will stall to allow stakeholders to catch up
  performanceFlag = true
  # Threshold of cpu usage above which coordinator will stall if performanceFlag = true
  systemLoadThreshold = 0.90
  # Number of values to average for load threshold
  numAverageLoad = 100
  # Execution context for prosomo actors
  stakeholder {
    executor = "thread-pool-executor"
    type = PinnedDispatcher
  }
  router {
    executor = "thread-pool-executor"
    type = PinnedDispatcher
  }
  coordinator {
    executor = "thread-pool-executor"
    type = PinnedDispatcher
  }
  tineProvider {
    executor = "thread-pool-executor"
    type = PinnedDispatcher
  }
  networkController {
    executor = "thread-pool-executor"
    type = PinnedDispatcher
  }
  stakeholderEC = "params.stakeholder"
  routerEC = "params.router"
  coordinatorEC = "params.coordinator"
  tineProviderEC = "params.tineProvider"
  networkControllerEC = "params.networkController"
  useRouterSystem = true


  ### Random Transactions ###
  # Issue random transactions if true
  transactionFlag = true
  # Chance of issuing transaction per coordinator update, e.g. 0.4 is 40 txs per second
  txProbability = 0.04
  # Max random transaction delta
  maxTransfer = 2.5e5


  ### Local Delay Model ###
  # Use router with delay model if true, use direct message passing if false
  useRouting = true
  # Delay in milliseconds per killometer in delay model
  delay_ms_km = 0.02
  # Delay in ms per byte in delay model
  delay_ms_byte = 2.0e-4
  # Added random delay from 0 to delay_ms_noise in milliseconds
  delay_ms_noise = 100.0


  ### Gossip ###
  # Number of holders to gossip for sending new blocks and transactions
  numGossipers = 3
  # Number of holders to gossip to upon forging
  numGossipersForge = 6


  ### Tinepool ###
  # Max number of tries for a tine to ask for parent blocks
  tineMaxTries = 10
  # Max depth that can be returned from an actor, number of blocks to send in response to fetch info hello message
  tineMaxDepth = 1000
  # Length of tine that triggers bootstrapping, set to < cacheSize/2
  tineBootstrappingDepth = 10


  ### Genesis Params ###
  # Number genesis of stakeholders
  numHolders = 32
  # Time scale for slot time and delay parameters
  timeScale = 1.0
  # Duration of slot in milliseconds
  slotT = 1000
  # Use network delay parameterization if true
  useDelayParam = false
  # Alert stake ratio
  alpha_s = 1.0
  # Participating stake ratio
  beta_s = 1.0
  # Epoch paramter
  epsilon_s = 0.081775
  # Checkpoint depth in blocks, k > 192*delta/epsilon*beta useDelayParam = true, default 2348
  k_n = 2348
  # Epoch length, R >= 3k/2f if useDelayParam = true, default 86400
  epochLength = 86400
  # Slot window for chain selection, s = k/4f if useDelayParam = true, default 14400
  slotWindow = 14400
  # Active slot coefficient, f <= 1-exp(1/(delta_s+1))*(1+epsilon_s)/(2.0*alpha_s) if useDelayParam = true
  f_s = 0.1
  # Order of accuracy for convergent series
  o_n = 16
  # Number of txs per block
  txPerBlock = 2000
  # Type of genesis stake distribution
  stakeDistribution = "flat"
  # Exponential scale factor for stake distribution
  stakeScale = 0.5
  # Max initial stake
  initStakeMax = 1.0e10
  # Min initial stake
  initStakeMin = 1000.0
  # Reward for forging blocks
  forgerReward = 1000000
  # Ratio of transaction amount taken as fee by the forger
  transactionFee = 0.01
  # Stake resource factor, must be greater than 0 and <= 1.0, for resource scaling regression
  resourceScale = 1.0


  ### Taktikos ###
  # Use Local Dynamic Difficulty if true, slot-gap-sawtooth cutoff profile curve with params set below
  f_dynamic = true
  # Sawtooth amplitude A
  f_A = 0.4
  # Baseline difficulty B
  f_B = 0.04
  # LDD cutoff in slots 'gamma'
  gamma = 40
  # Slot gap 'psi'
  slot_gap = 0
  # Forging window in slots
  forging_window = 40
  # Forging window checkpoint depth 'kappa'
  kappa = 1
  # Add stabilizing term, forging_window*(s_{n-kappa} / forging_window + 1)
  useStableIntervalTerm = false
  # Test value strategy in staking procedure, experimental
  testStrategy = "vrf"
  # Use maxvalid-tk chain selection rule
  useMaxValidTK = true
  # maxvalid-tk checkpoint depth in blocks (kbar)
  k_bar = 1


  ### Local Only Features ###
  # Use fencing and action based round progression to enforce deterministic runs, set true for deterministic run
  useFencing = false
  # Record data if true, plot data points with ./cmd.sh and enter command: plot
  dataOutFlag = false
  # Interval in slots between datapoints
  dataOutInterval = 3600
  # Set to true to use disk storage
  storageFlag = true
  # Maximum block number after which printing holder will terminate simulation, set to zero for no limit
  maxBlockNumber = 1000
  # Write the current genesis block to resources at runtime, used for testnet releases
  writeGenBlock = false
  # Label for filenames
  simLabel = "default"

}

bifrost {

  application {
    # application version of this software
    version { value = 1.7.6 }

    # directory where all network data is stored
    dataDir = ".bifrost/private-testnet/data"

    # directory where the keyfiles used for forging are stored
    keyFileDir = ".bifrost/private-testnet/keyfiles"

    # enables the Program Box Registry, this is needed to process program transactions
    enablePBR = true

    # enables the Token Box Registry, this is needed to process transfer transactions
    enableTBR = true

    # optional set of accounts that will be tracked by the state of this node
    nodeKeys = []

    # time an unconfirmed transaction can stay in the mempool before being removed
    mempoolTimeout = 3h

    # Number of transactions from mempool to be re-broadcasted
    rebroadcastCount = 3

    # ----- Cache settings (Guava) -----
    # Consider 5 sec per block for testing and 15 sec per block for toplnet
    # 15 sec * 50 blocks / 60 sec per minutes = 12.5 minutes
    # using milliseconds: 1,200,000 milliseconds == 20 minutes
    cacheExpire = 1200000
    cacheSize = 50000
  }

  rpcApi {
    # Local network address to bind to
    bindAddress = "0.0.0.0:9085"

    # Setting this to true allows the node to receive API requests without checking for a valid API key
    disableAuth = false

    # Hash of the API key string
    apiKeyHash = ""

    # Time allowed to process a request
    timeout = 30s

    # Return stack traces on API error
    verboseAPI = true

    # Set the state of the different namespace (this allows a node to enable/disable certain API functionality)
    namespaceSelector {
        topl = true
        util = true
        admin = true
        debug = false
    }
  }

  gjallarhorn {
    # enables connections to Gjallarhorn wallets to be made
    enableWallet = false

    # Turn on to enable connections to Gjallarhorn applications
    clusterEnabled = false

    # Local address to bind Akka cluster to
    clusterHost = "127.0.0.1"

    # Local port to bind Akka cluster to
    clusterPort = 9087
  }


  network {

    #####################################################
    # Node information to be declared during handshake  #
    #####################################################

    # Node name to send during handshake
    nodeName = "Bifrost"

    # Network agent name. May contain information about client code
    # stack, starting from core code-base up to the end graphical interface.
    # Basic format is `/Name:Version(comments)/Name:Version/.../`,
    # e.g. `/Topl-Scala-client:1.0.0(Windows; U; CPU OS 3_2_1)/`
    agentName = "bifrost"

    # Limit the size of allowed agent names
    applicationNameLimit = 50

    # Network address
    bindAddress = "0.0.0.0:9084"

    ########################
    # Connection settings  #
    ########################

    # Magic bytes, that will be added to every p2p message to allow
    # distinguish different networks (e.g. testnet/mainnet).
    magicBytes = [7, -30, 19, 92]

    # String with IP address and port to send as external address during handshake.
    # Could be set automatically if UPnP is enabled.
    #
    # If `declared-address` is set, which is the common scenario for nodes running in the cloud,
    # the node will just listen to incoming connections on `bindAddress:port` and
    # broadcast its `declaredAddress` to its peers.
    # UPnP is supposed to be disabled in this scenario.
    #
    # If declared address is not set and UPnP is not enabled, the node will not be reachable from
    # external networks (outside your LAN)
    #
    # If declared address is not set and UPnP is enabled, the node will attempt to connect to an IGD, retrieve its
    # external IP address and configure the gateway to allow traffic through. If the node succeeds, the gateway devices external
    # IP address becomes the node's declared address.
    #
    # In some cases, you may both set `declaredAddress` and enable UPnP (e.g. when IGD can't reliably determine its
    # external IP address). In such cases the node will attempt to configure an IGD to pass traffic from external port
    # to `bind-address:port`. Please note, however, that this setup is not recommended.
    # declaredAddress = ""

    # Enable UPnP tunnel creation only if you router/gateway supports it. Useful if your node is running in home
    # network. Completely useless if you node is in cloud.
    upnpEnabled = false

    # When UPnP is enabled, should a random port be mapped?
    upnpUseRandom = true

    # UPnP timeouts
    upnpGatewayTimeout = 7s
    upnpDiscoverTimeout = 3s

    # Network controller timeout
    controllerTimeout = 5s

    ##################
    # Peers settings #
    ##################

    # Network handshake timeout
    handshakeTimeout = 5000ms

    # List of IP addresses of well known nodes.
    knownPeers = []

    # Interval between GetPeers messages to be send by our node to a random one
    getPeersInterval = 2m

    # Number of network connections
    maxConnections = 20

    # Network connection timeout
    connectionTimeout = 1s

    # Period of time to wait deeming a connection dead and dropping it
    deadConnectionTimeout = 10m

    ############################
    # Delivery settings limits #
    ############################

    # Network delivery timeout
    deliveryTimeout = 10s

    # Max number of delivery checks. Total time spent waiting on any modifier is (2 * maxDeliveryChecks * deliveryTimeout)
    maxDeliveryChecks = 40

    ########################
    # SyncTracker Timeouts #
    ########################

    # Interval between `SyncInfo` messages when our node is not synchronized yet
    syncInterval = 10s

    # Interval between `SyncInfo` messages when our node is already synchronized
    syncIntervalStable = 20s

    # Synchronization timeout
    syncTimeout = 5s

    # Synchronization status update interval
    syncStatusRefresh = 2m

    # Synchronization status update interval for stable regime
    syncStatusRefreshStable = 4m

    ###############
    # Size limits #
    ###############

    # Maximum income package size (bytes)
    maxPacketSize = 1048576

    # Maximum size of a handshaking message (bytes)
    maxHandshakeSize = 8096

    # Accept maximum inv objects
    maxInvObjects = 512

    # Desired number of inv objects. Our requests will have this size.
    desiredInvObjects = 512

    # How many persistent modifiers to store in the cache.
    # The cache stores modifiers that are waiting to be applied.
    maxModifiersCacheSize = 1024

    # How deep below the height of the chain should we consider forks?
    maxChainCacheDepth = 1024

    # Maximum number of PeerSpec objects in one Peers message
    maxPeerSpecObjects = 64

    # Default ban duration, unless permanent penalty is applied
    temporalBanDuration = 60m

    # Misbehaving peer penalty score will not be increased withing this time interval,
    # unless permanent penalty is applied
    penaltySafeInterval = 5m

    # Max penalty score peer can accumulate before being banned
    penaltyScoreThreshold = 100
  }

  forging {

    # number of attempts to forge per block time
    blockGenerationDelay = 1 second

    # minimum transaction fee this node will enforce for including transactions into blocks
    minTransactionFee = 0 #nanoPolys (1 Poly = 10^9 nanoPolys)

    # controls whether forging is attempted immediately following startup
    forgeOnStartup = false

    # optional rewards address where block rewards and fees will be sent
    #rewardsAddress =

    # settings required for private networks
    privateTestnet {

      # optional string used to seed keyfile creation
      #genesisSeed =

      # the number of accounts to create
      numTestnetAccts = 10

      # the Arbit and Poly balance of each account
      testnetBalance = 1000000

      # Difficulty the genesis block is created with
      initialDifficulty = 1000000000000000000
    }

    protocolVersions = [
      # Version.value: maximum applicable software version for these protocol settings
      # startBlock: starting block height for these protocol settings
      # blockVersion: applicable block serializer version
      # targetBlockTime: Agreed upon block time target
      # numTxPerBlock: number of transactions per block

      {
        version { value = 1.0.0 }
        startBlock = 0
        blockVersion = 1
        targetBlockTime = 3 seconds
        numTxPerBlock = 100
      }
    ]
  }

  ntp {
    # NTP server address
    server = "pool.ntp.org"

    # update time rate
    updateEvery = 30m

    # server answer timeout
    timeout = 30s
  }
}

akka {
  jvm-shutdown-hooks = off
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  log-dead-letters = on
  actor {
    debug {
      receive = on
      autoreceive = on
      unhandled = on
      lifecycle = on
      event-stream = on
    }
  }
}

# Service to monitor performance
kamon {

  # Enable/disable monitoring
  enable = false

  environment.service = "bifrost"
  # apm.api-key = ""

  trace.join-remote-parents-with-same-span-id = yes
  metric.tick-interval = 60 seconds

  influxdb {
    hostname = "localhost"
    port = 8086
    database = "mydb"
    subscriptions {
      akka-actor = ["**"]
      akka-dispatcher = ["**"]
    }
  }

  zipkin {
    hostname = "localhost"
    port = 9411
    protocol = "http"
  }

  instrumentation {
    akka.filters {
      doomsday-wildcard = on
      actors {
        track {
          includes = ["**"]
          excludes = []
        }
        start-trace {
          includes = ["**"]
        }
        trace {
          includes = ["**"]
        }
      }
      dispatchers {
        includes = ["**"]
      }
    }

    akka.http {
      server {
        propagation {
          enabled = yes
          channel = default
        }
        tracing {
          enabled = yes
          span-metrics = on
        }
      }
      client {
        propagation {
          enabled = yes
          channel = default
        }
        tracing {
          enabled = yes
          span-metrics = on
        }
      }
    }
  }
}
